# union_chatbot_app.py
# -*- coding: utf-8 -*-

import os
from pathlib import Path
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬", layout="centered")

# ğŸ’¡ ì „ì²´ ë°°ê²½ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” CSS
st.markdown(
    """
    <style>
        .stApp {
            background-color: white !important;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# OpenAI API í‚¤ ì„¤ì •
try:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except (KeyError, AttributeError):
    openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
PDF_FILES_DIR = BASE_DIR / "data"
PDF_FILES = [
    "policy_agenda_250627.pdf",
    "union_meeting_250704.pdf"
]

# UI êµ¬ì„±
st.markdown("""
<style>
    .stApp { background-color: white; }
    .stSpinner > div > div { border-top-color: #0062ff; }
    .stSuccess {
        background-color: #e6f7ff;
        border: 1px solid #91d5ff;
        border-radius: 8px;
        color: #0050b3;
    }
</style>
""", unsafe_allow_html=True)

st.image("1.png", width=300)

st.markdown("""
    <style>
    .footer-left {
        position: fixed;
        bottom: 10px;
        left: 10px;
        font-size: 12px;
        color: #555;
        line-height: 1.5;
        z-index: 100;
    }
    </style>

    <div class="footer-left">
        ìˆ˜ì›ì‹œ ì˜í†µêµ¬ ë§¤ì˜ë¡œ 159ë²ˆê¸¸ 19, ê´‘êµ ë” í¼ìŠ¤íŠ¸ ì§€ì‹ì‚°ì—…ì„¼í„°<br>
        ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸: 133-82-71927 ï½œ ëŒ€í‘œ: ì‹ í›ˆì‹ ï½œ ëŒ€í‘œë²ˆí˜¸: 010-9496-6517<br>
        ì´ë©”ì¼: <a href="mailto:hoonsik79@hanmail.net">hoonsik79@hanmail.net</a>
    </div>
""", unsafe_allow_html=True)

st.markdown("<h1 style='display:inline-block; vertical-align:middle; margin-left:10px; color: #0d1a44;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>", unsafe_allow_html=True)
st.write("ì•ˆë…•í•˜ì„¸ìš”!ë…¸ì¡° ì§‘í–‰ë¶€ì—ì„œ ì—…ë¡œë“œ í•œ ìë£Œì— ê¸°ë°˜í•˜ì—¬ ë…¸ì¡° ë° íšŒì‚¬ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤. ì•„ë˜ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

# ë¬¸ì„œ ë¡œë”© ë° ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def load_all_documents(pdf_paths):
    all_docs = []
    for path in pdf_paths:
        if path.exists():
            try:
                loader = PyPDFLoader(str(path))
                all_docs.extend(loader.load())
            except Exception as e:
                st.warning(f"'{path.name}' íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        else:
            st.warning(f"'{path.name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    return all_docs

@st.cache_resource
def split_documents_into_chunks(_documents):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    return text_splitter.split_documents(_documents)

@st.cache_resource
def create_vector_store(_texts, _embedding_model):
    try:
        return FAISS.from_documents(_texts, _embedding_model)
    except Exception as e:
        st.error(f"ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

# ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„±
@st.cache_resource
def initialize_qa_chain():
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    full_pdf_paths = [PDF_FILES_DIR / fname for fname in PDF_FILES]
    documents = load_all_documents(full_pdf_paths)
    if not documents:
        st.error("âŒ ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'data' í´ë”ì— PDF íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    text_chunks = split_documents_into_chunks(documents)
    db = create_vector_store(text_chunks, embeddings)
    retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 3})
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-4o", temperature=0)
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

# ì•± ì‹¤í–‰
try:
    qa_chain = initialize_qa_chain()
except Exception as e:
    st.error(f"ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

query = st.text_input(
    "[ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.]",
    placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”",
    key="query_input"
)

if query:
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        try:
            result = qa_chain.invoke({"query": query})
            answer_text = result["result"].strip()

            if not answer_text or ("ì •ë³´" in answer_text and "ì—†" in answer_text):
                st.info("ì£„ì†¡í•˜ì§€ë§Œ ì œê³µëœ ì •ë³´ì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
            else:
                st.success(answer_text)

            with st.expander("ğŸ“„ ë‹µë³€ ê·¼ê±° ë¬¸ì„œ ë³´ê¸°"):
                for i, doc in enumerate(result["source_documents"]):
                    source_name = Path(doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')).name
                    page = doc.metadata.get('page')
                    page_number = page + 1 if isinstance(page, int) else "ì•Œ ìˆ˜ ì—†ìŒ"
                    st.markdown(f"**ë¬¸ì„œ {i+1}:** `{source_name}` (í˜ì´ì§€: {page_number})")
                    st.write(f'"{doc.page_content.strip()[:500]}..."')
                    st.markdown("---")
        except Exception as e:
            st.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
