import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ğŸ” API í‚¤ ë¡œë”©
openai_api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# ğŸ“˜ ë¬¸ì„œ ë¡œë”© í•¨ìˆ˜
def load_documents():
    loaders = []
    for filename in os.listdir("./data"):
        if filename.endswith(".pdf"):
            loaders.append(PyPDFLoader(f"./data/{filename}"))
    documents = []
    for loader in loaders:
        documents.extend(loader.load())
    return documents

# ğŸ“„ í…ìŠ¤íŠ¸ ë¶„í• 
def split_documents(docs):
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    return splitter.split_documents(docs)

# ğŸ§  ë²¡í„° DB ìƒì„± í•¨ìˆ˜ (ì—ëŸ¬ ë°©ì§€ ë° ì¸ì½”ë”© ì²˜ë¦¬)
@st.cache_data(show_spinner="ğŸ“Š ë²¡í„° DB ìƒì„± ì¤‘...")
def create_vector_db(docs, embedding_model):
    try:
        contents = [doc.page_content for doc in docs]
        safe_contents = [
            str(text).encode("utf-8", errors="ignore").decode("utf-8")
            for text in contents
        ]
        vectors = embedding_model.embed_documents(safe_contents)
        return FAISS.from_texts(safe_contents, embedding_model)
    except Exception as e:
        st.error(f"âŒ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.stop()

# ğŸ”§ ì „ì²´ íŒŒì´í”„ë¼ì¸
def load_or_create_vector_db():
    documents = load_documents()
    texts = split_documents(documents)
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    return create_vector_db(texts, embeddings)

# ğŸ§  LLM QA ì²´ì¸ ìƒì„±
@st.cache_data(show_spinner="ğŸ¤– ì±—ë´‡ ë¡œë”© ì¤‘...")
def get_qa_chain(db):
    retriever = db.as_retriever()
    return RetrievalQA.from_chain_type(
        llm=ChatOpenAI(openai_api_key=openai_api_key, temperature=0),
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

# ğŸ’» Streamlit UI
st.image("1.png", width=110)
st.markdown("<h1 style='display:inline-block; margin-left:10px;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>", unsafe_allow_html=True)
st.write("ì•ˆë…•í•˜ì„¸ìš”! ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ë…¸ì¡° ê´€ë ¨ ìë£Œì—ì„œ ìë™ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

# ğŸ“¦ DB ë° ì²´ì¸ ì¤€ë¹„
db = load_or_create_vector_db()
qa_chain = get_qa_chain(db)

# ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", placeholder="ì˜ˆ: 7ì›” ì •ê¸°í˜‘ì˜ ì£¼ìš” ì˜ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?")

# ğŸ’¬ ì‘ë‹µ ì¶œë ¥
if query:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        result = qa_chain(query)
        st.success(result["result"])

        # ğŸ” ì°¸ê³  ë¬¸ì„œ
        with st.expander("ğŸ“ ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
            for i, doc in enumerate(result["source_documents"]):
                st.markdown(f"**ë¬¸ì„œ {i+1}:** {doc.metadata['source']}")
                st.write(doc.page_content[:1000])  # 1000ì ë¯¸ë¦¬ë³´ê¸°

# ğŸ”„ í…ìŠ¤íŠ¸ ë¶„í•  ì „ ì²˜ë¦¬
docs_raw = documents1 + documents2

# í•œê¸€ í¬í•¨ ë¬¸ì„œì˜ ìœ ë‹ˆì½”ë“œ ì˜¤ë¥˜ ë°©ì§€
for doc in docs_raw:
    try:
        doc.page_content = doc.page_content.encode('utf-8').decode('utf-8')
    except UnicodeEncodeError:
        st.warning("âš ï¸ ë¬¸ì„œ ì¸ì½”ë”© ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.stop()

# í…ìŠ¤íŠ¸ ë¶„í• 
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
texts = text_splitter.split_documents(docs_raw)

