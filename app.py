import os
import streamlit as st
import time
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# ğŸ”‘ OpenAI API í‚¤ ì„¤ì •
openai_api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# ğŸŒ ì‚¬ìš©ì UI
st.image("1.png", width=110)
st.markdown("<h1 style='display:inline-block; margin-left:10px;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>", unsafe_allow_html=True)
st.write("ì•ˆë…•í•˜ì„¸ìš”! ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ë…¸ì¡° ê´€ë ¨ ìë£Œì—ì„œ ìë™ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

# ğŸ“ ë²¡í„° DB ê²½ë¡œ
VECTOR_DB_PATH = "faiss_index"

# ğŸ“‚ PDF ë¡œë”©
def load_documents():
    loader1 = PyPDFLoader("./data/25ë…„ ì •ë¶€ ë…¸ë™ì •ì±… ì£¼ìš” ì•„ì  ë‹¤(250627).pdf")
    loader2 = PyPDFLoader("./data/ì¡´ì¤‘ë…¸ì¡° ë…¸ì‚¬ ì •ê¸°í˜‘ì˜ì²´(250704).pdf")
    documents1 = loader1.load()
    documents2 = loader2.load()
    return documents1 + documents2

# ğŸ§  ë²¡í„° DB ìƒì„±
def create_vector_db(texts, embeddings):
    docs_embedded = []
    batch_size = 10

    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        try:
            embedded = embeddings.embed_documents([d.page_content for d in batch])
            for doc, vec in zip(batch, embedded):
                doc.embedding = vec
                docs_embedded.append(doc)
            time.sleep(1.2)  # Rate limit ì™„í™”
        except Exception as e:
            st.warning(f"âš ï¸ {i}ë²ˆì§¸ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            time.sleep(5)

    db = FAISS.from_documents(docs_embedded, embeddings)
    db.save_local(VECTOR_DB_PATH)
    return db

# ğŸ“Œ ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸° ë˜ëŠ” ìƒì„±
def load_or_create_vector_db():
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

    if os.path.exists(VECTOR_DB_PATH):
        try:
            db = FAISS.load_local(VECTOR_DB_PATH, embeddings)
            return db
        except Exception as e:
            st.warning("âŒ ê¸°ì¡´ ë²¡í„° DB ë¡œë“œ ì‹¤íŒ¨. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
            os.remove(VECTOR_DB_PATH)

    # ìƒˆë¡œ ìƒì„±
    documents = load_documents()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.split_documents(documents)
    return create_vector_db(texts, embeddings)

# âœ… ë²¡í„° DB ë¡œë”©
db = load_or_create_vector_db()
retriever = db.as_retriever()

# ğŸ¤– ì±—ë´‡ ì²´ì¸ êµ¬ì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(openai_api_key=openai_api_key, temperature=0),
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True
)

# ğŸ’¬ ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ì°½
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", placeholder="ì˜ˆ: 7ì›” ì •ê¸°í˜‘ì˜ ì£¼ìš” ì˜ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?")

if query:
    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
        try:
            result = qa_chain(query)
            st.success(result["result"])

            # ğŸ“ ì°¸ì¡° ë¬¸ì„œ ë³´ì—¬ì£¼ê¸°
            with st.expander("ğŸ“ ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
                for i, doc in enumerate(result["source_documents"]):
                    st.markdown(f"**ë¬¸ì„œ {i+1}:** {doc.metadata['source']}")
                    st.write(doc.page_content[:1000])  # ë¯¸ë¦¬ë³´ê¸° ì œí•œ
        except Exception as e:
            st.error(f"âš ï¸ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
