import os
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# âœ… OpenAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
openai_api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

# âœ… ë¬¸ì„œ ë¡œë”© í•¨ìˆ˜ (PDF 2ê°œ)
@st.cache_resource
def load_documents():
    loader1 = PyPDFLoader("./data/25ë…„ ì •ë¶€ ë…¸ë™ì •ì±… ì£¼ìš” ì•„ì  ë‹¤(250627).pdf")
    loader2 = PyPDFLoader("./data/ì¡´ì¤‘ë…¸ì¡° ë…¸ì‚¬ ì •ê¸°í˜‘ì˜ì²´(250704).pdf")
    docs = loader1.load() + loader2.load()

    # ğŸ” í•œê¸€ ì¸ì½”ë”© ì˜¤ë¥˜ ë°©ì§€
    for doc in docs:
        try:
            doc.page_content = doc.page_content.encode('utf-8').decode('utf-8')
        except UnicodeEncodeError:
            st.warning("âš ï¸ ì¼ë¶€ ë¬¸ì„œì—ì„œ ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            st.stop()

    return docs

# âœ… ë²¡í„° DB ìƒì„± í•¨ìˆ˜
@st.cache_resource
def load_or_create_vector_db():
    documents = load_documents()
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    return FAISS.from_documents(texts, embeddings)

# âœ… QA ì²´ì¸ ìƒì„± í•¨ìˆ˜
@st.cache_resource
def get_qa_chain():
    db = load_or_create_vector_db()
    retriever = db.as_retriever()
    llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0)
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

# âœ… Streamlit ì‚¬ìš©ì UI
st.image("1.png", width=110)
st.markdown("<h1 style='display:inline-block; margin-left:10px;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>", unsafe_allow_html=True)
st.write("ì•ˆë…•í•˜ì„¸ìš”! ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ë…¸ì¡° ê´€ë ¨ ìë£Œì—ì„œ ìë™ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

# âœ… ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", placeholder="ì˜ˆ: 7ì›” ì •ê¸°í˜‘ì˜ ì£¼ìš” ì˜ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?")

# âœ… ì‘ë‹µ ì²˜ë¦¬
if query:
    qa_chain = get_qa_chain()
    with st.spinner("âœï¸ ë‹µë³€ ìƒì„± ì¤‘..."):
        result = qa_chain(query)
        st.success(result["result"])

        # ğŸ“ ì¶œì²˜ ë¬¸ì„œ í‘œì‹œ
        with st.expander("ğŸ“š ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
            for i, doc in enumerate(result["source_documents"]):
                st.markdown(f"**ë¬¸ì„œ {i+1}:** {doc.metadata['source']}")
                st.write(doc.page_content[:1000])
