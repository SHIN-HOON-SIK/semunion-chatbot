import os import sys import io import streamlit as st from langchain_community.document_loaders import PyPDFLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain_community.vectorstores import FAISS from langchain.embeddings.openai import OpenAIEmbeddings from langchain.chat_models import ChatOpenAI from langchain.chains import RetrievalQA

âœ… ì‹œìŠ¤í…œ ì¶œë ¥ ì¸ì½”ë”© ì„¤ì • (UnicodeEncodeError ë°©ì§€)

sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

âœ… ì „ì²˜ë¦¬ í•¨ìˆ˜ (í…ìŠ¤íŠ¸ ë‚´ íŠ¹ìˆ˜ë¬¸ìë‚˜ ë¹„ASCII ë¬¸ì ì •ë¦¬)

def clean_text(text): return text.encode("utf-8", errors="ignore").decode("utf-8")

ğŸ”‘ OpenAI API í‚¤

openai_api_key = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv("OPENAI_API_KEY") if not openai_api_key: st.error("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") st.stop()

ğŸŒ ì‚¬ìš©ì UI

st.image("1.png", width=110) st.markdown("<h1 style='display:inline-block; margin-left:10px;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>", unsafe_allow_html=True) st.write("ì•ˆë…•í•˜ì„¸ìš”! ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ë…¸ì¡° ê´€ë ¨ ìë£Œì—ì„œ ìë™ìœ¼ë¡œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")

ğŸ“‚ PDF ë¬¸ì„œ ë¡œë”©

loader1 = PyPDFLoader("./data/25_government_agenda.pdf") loader2 = PyPDFLoader("./data/respect_union_agenda.pdf") loader3 = PyPDFLoader("./data/external_audit_preparation.pdf")  # ìƒˆ ë¬¸ì„œ ì¶”ê°€

documents = loader1.load() + loader2.load() + loader3.load()

ğŸ”„ í…ìŠ¤íŠ¸ ë¶„í•  + ì „ì²˜ë¦¬ ì ìš©

text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100) texts = text_splitter.split_documents(documents) contents = [clean_text(doc.page_content) for doc in texts]

ğŸ§  ì„ë² ë”© + ë²¡í„° DB ìƒì„±

embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key) db = FAISS.from_texts(contents, embeddings) retriever = db.as_retriever()

ğŸ¤– ì±—ë´‡ ìƒì„±

qa_chain = RetrievalQA.from_chain_type( llm=ChatOpenAI(openai_api_key=openai_api_key, temperature=0), chain_type="stuff", retriever=retriever, return_source_documents=True )

ğŸ’¬ ì‚¬ìš©ì ì…ë ¥

query = st.text_input("ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", placeholder="ì˜ˆ: ì™¸ë¶€ íšŒê³„ê°ì‚¬ ì¤€ë¹„ ë‚´ìš©ì€?")

if query: with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."): result = qa_chain(query) st.success(result["result"])

# ğŸ” ì°¸ì¡° ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°
    with st.expander("ğŸ“ ê´€ë ¨ ë¬¸ì„œ ë³´ê¸°"):
        for i, doc in enumerate(result["source_documents"]):
            st.markdown(f"**ë¬¸ì„œ {i+1}:** {doc.metadata['source']}")
            st.write(doc.page_content[:1000])

