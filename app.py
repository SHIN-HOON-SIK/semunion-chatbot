# union_chatbot_app.py
# -*- coding: utf-8 -*-

import os
from pathlib import Path
import streamlit as st
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.schema import Document, HumanMessage

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬",
    layout="centered",
    page_icon="logo_union_hands.png"
)

# ğŸ’¡ ì „ì²´ ë°°ê²½ í°ìƒ‰ + ì¢Œì¸¡ í•˜ë‹¨ ì •ë³´ í‘œê¸° CSS
st.markdown(
    """
    <style>
        .stApp {
            background-color: white !important;
        }
        .footer-left {
            position: fixed;
            bottom: 10px;
            left: 10px;
            font-size: 12px;
            color: #555;
            line-height: 1.5;
            z-index: 100;
        }
    </style>
    <div class="footer-left">
        ìˆ˜ì›ì‹œ ì˜í†µêµ¬ ë§¤ì˜ë¡œ 159ë²ˆê¸¸ 19, ê´‘êµ ë” í¼ìŠ¤íŠ¸ ì§€ì‹ì‚°ì—…ì„¼í„°<br>
        ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸: 133-82-71927 ï½œ ëŒ€í‘œ: ì‹ í›ˆì‹ ï½œ ëŒ€í‘œë²ˆí˜¸: 010-9496-6517<br>
        ì´ë©”ì¼: <a href="mailto:hoonsik79@hanmail.net">hoonsik79@hanmail.net</a>
    </div>
    """,
    unsafe_allow_html=True
)

# OpenAI API í‚¤ ì„¤ì •
try:
    openai_api_key = st.secrets["OPENAI_API_KEY"]
except (KeyError, AttributeError):
    openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
PDF_FILES_DIR = BASE_DIR / "data"
PDF_FILES = [
    "policy_agenda_250627.pdf",
    "union_meeting_250704.pdf",
    "SEMUNION_DATA_BASE.pdf"
]

# UI êµ¬ì„±
st.markdown(
    """
    <div style='display: flex; align-items: center; justify-content: center; gap: 10px; margin-bottom: 10px;'>
        <img src="https://raw.githubusercontent.com/SHIN-HOON-SIK/semunion-chatbot/main/logo_union_hands.png" width="50"/>
        <h1 style='color: #0d1a44; margin: 0;'>ì‚¼ì„±ì „ê¸° ì¡´ì¤‘ë…¸ë™ì¡°í•© ìƒë‹´ì‚¬</h1>
    </div>
    """,
    unsafe_allow_html=True
)

st.write("ì•ˆë…•í•˜ì„¸ìš”! ë…¸ì¡° ì§‘í–‰ë¶€ì—ì„œ ì—…ë¡œë“œ í•œ ìë£Œì— ê¸°ë°˜í•˜ì—¬ ë…¸ì¡° ë° íšŒì‚¬ ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€í•´ ë“œë¦½ë‹ˆë‹¤. ì•„ë˜ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")

# ë¬¸ì„œ ë¡œë”© ë° ì²˜ë¦¬ í•¨ìˆ˜
@st.cache_resource
def load_all_documents(pdf_paths):
    all_docs = []
    for path in pdf_paths:
        if path.exists():
            try:
                loader = PyPDFLoader(str(path))
                all_docs.extend(loader.load())
            except Exception as e:
                st.warning(f"'{path.name}' íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨. PDF ì¸ì½”ë”© ë¬¸ì œë¡œ ìƒëµë©ë‹ˆë‹¤.")
        else:
            st.warning(f"'{path.name}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    return all_docs

@st.cache_resource
def split_documents_into_chunks(_documents):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    return text_splitter.split_documents(_documents)

@st.cache_resource
def create_vector_store(_texts, _embedding_model):
    try:
        return FAISS.from_documents(_texts, _embedding_model)
    except Exception as e:
        st.error(f"ë²¡í„° DB ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        st.stop()

# ì§ˆì˜ì‘ë‹µ ì²´ì¸ êµ¬ì„±
@st.cache_resource
def initialize_qa_chain(k):
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    full_pdf_paths = [PDF_FILES_DIR / fname for fname in PDF_FILES]
    documents = load_all_documents(full_pdf_paths)
    if not documents:
        st.error("âŒ ë¡œë“œí•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. 'data' í´ë”ì— PDF íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()
    text_chunks = split_documents_into_chunks(documents)
    db = create_vector_store(text_chunks, embeddings)
    retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": k})
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-4o", temperature=0)
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True
    )

# ì§ˆë¬¸ ë³´ì •ìš© í™•ì¥ í•¨ìˆ˜
@st.cache_resource
def get_query_expander():
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        model_name="gpt-4o",
        temperature=0
    )
    def expand(query):
        try:
            query_utf8 = query.encode("utf-8", "ignore").decode("utf-8")
            prompt = HumanMessage(content=(
                "ë‹¤ìŒ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ë¬¸ì¥ìœ¼ë¡œ ë°”ê¿”ì¤˜.\n"
                "ì˜ˆì‹œ: 'ì§‘í–‰ë¶€' â†’ 'ì¡´ì¤‘ë…¸ë™ì¡°í•©ì˜ ì§‘í–‰ë¶€ êµ¬ì„±ì€ ì–´ë–»ê²Œ ë˜ì–´ ìˆë‚˜ìš”?'\n"
                f"ì§ˆë¬¸: {query_utf8}"
            ))
            response = llm.invoke([prompt])
            return response.content.strip() if hasattr(response, 'content') else response
        except Exception as e:
            st.warning("â• ì§ˆë¬¸ í™•ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {}".format(str(e)))
            return query
    return expand

# ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ê°œìˆ˜ ì¡°ì ˆ
k_value = st.sidebar.number_input("ğŸ” ìœ ì‚¬ë¬¸ì„œ ê²€ìƒ‰ ê°œìˆ˜ (k)", min_value=1, max_value=20, value=1)

# ì•± ì‹¤í–‰
try:
    qa_chain = initialize_qa_chain(k_value)
    query_expander = get_query_expander()
except Exception as e:
    st.error(f"ì±—ë´‡ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    st.stop()

raw_query = st.text_input(
    "[ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.]",
    placeholder="ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.",
    key="query_input"
)

query = query_expander(raw_query) if raw_query else ""

if query:
    with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
        try:
            result = qa_chain.invoke({"query": query})
            answer_text = result["result"]

            if not answer_text or ("ì •ë³´" in answer_text and "ì—†" in answer_text):
                st.info("ì£„ì†¡í•˜ì§€ë§Œ ì§‘í–‰ë¶€ê°€ ì—…ë¡œë“œ í•œ ìë£Œì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹ ë¥¸ ì—…ë°ì´íŠ¸í•˜ê² ìŠµë‹ˆë‹¤.")
            else:
                st.success(answer_text)

            with st.expander("ğŸ“„ ë‹µë³€ ê·¼ê±° ë¬¸ì„œ ë³´ê¸°"):
                for i, doc in enumerate(result["source_documents"]):
                    source_name = Path(doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')).name
                    page = doc.metadata.get('page')
                    page_number = page + 1 if isinstance(page, int) else "ì•Œ ìˆ˜ ì—†ìŒ"
                    st.markdown(f"**ë¬¸ì„œ {i+1}:** `{source_name}` (í˜ì´ì§€: {page_number})")
                    try:
                        raw = doc.page_content.strip().replace("\u0000", "")[:500]
                        content = raw.encode('utf-8', 'ignore').decode('utf-8')
                        st.write(content + "...")
                    except Exception as e:
                        st.warning(f"ğŸ“ ë¬¸ì„œ ë‚´ìš©ì„ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.markdown("---")
        except Exception as e:
            error_text = str(e)
            st.error(f"âŒ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_text}")
